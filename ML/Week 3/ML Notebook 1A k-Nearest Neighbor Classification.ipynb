{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzvqnncwLgar"
   },
   "source": [
    "# Notebook 1A:  k-Nearest Neighbor (kNN) Classification\n",
    "Organized and prepared by Christopher Monterola, updated by Kenneth Co. and Gino Borja\n",
    "\n",
    "This notebook was conceptualized, organized, and primarily prepared for the **Machine Learning** course.\n",
    "\n",
    "### This notebook uses the following references:\n",
    "- Introduction to Machine Learning with Python, A. Mueller and S. Guido, O'Reilly 2017\n",
    "- https://kevinzakka.github.io/2016/07/13/k-nearest-neighbor/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4Em4PjXBhlz"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "There are two major types of supervised learning problems:\n",
    "- **Classification** when the goal is to predict a class label, which is a choice from a predefined list of possibilities\n",
    "- **Regression** when the goal is to predict a continuous number, or a floating-point number (data scientists, computer scientist) or real number (mathematician).\n",
    "\n",
    "----\n",
    "\n",
    "The kNN classifier is a ***non-parametric*** and *instance-based* learning algorithm.\n",
    "- ***Non-parametric*** means it makes no explicit assumptions about the functional form of the mapping, avoiding the dangers of mismodeling the underlying distribution of the data. For example, suppose our data is highly non-Gaussian but the learning model we choose assumes a Gaussian form. In that case, our algorithm would make extremely poor predictions.\n",
    "- ***Instance-based*** learning means that our algorithm doesn’t explicitly learn a model. Instead, it chooses to memorize the training instances which are subsequently used as “knowledge” for the prediction phase. Concretely, this means that only when a query to our database is made (i.e. when we ask it to predict a label given an input),  the algorithm will use the training instances to spit out an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15814,
     "status": "ok",
     "timestamp": 1712824496177,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "mVa3fkoF4qjI",
    "outputId": "72a889d8-593c-4ea9-a006-5596a743ba26"
   },
   "outputs": [],
   "source": [
    "!pip install -U mglearn\n",
    "!pip install --upgrade joblib==1.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4Hmn384TqqN"
   },
   "source": [
    "## Formulation\n",
    "\n",
    "Consider a training set with $N$ samples given by {$X_1, X_2, \\ldots, X_N$} with the corresponding targets {$y_1, y_2, \\ldots, y_N$}, where each of the ${X_i}$ data set contains $M$ features, for example:\n",
    "- for i = 1: {$X_1$} ={$x_1^a, x_1^b, \\ldots, x_1^M$} with target $y_1$\n",
    "- for i = 2: {$X_2$} ={$x_2^a, x_2^b, \\ldots, x_2^M$} with target $y_2$, ...\n",
    "- for i = N: {$X_N$} ={$x_N^a, x_N^b, \\ldots, x_N^M$} with target $y_N$\n",
    "\n",
    "then the  target of a given feature set $q$ {$x_q^a, x_q^b, \\dots, x_q^M$},chosen from 1 to $N$,  is the $y_i$ that gives the smallest euclidean distance $d_q^i$ from feature set $i$ {$x_i^a, x_i^b, \\dots, x_i^M$}\n",
    "\n",
    "\\begin{equation}\n",
    "d_q^i= \\sqrt{(x_i^a-x_q^a)^2 + (x_i^b-x_q^b)^2 + \\ldots + (x_i^M-x_q^M)^2}\n",
    "\\end{equation}\n",
    "\n",
    "Don't worry if this is confusing now! You will better appreciate the above math by considering the illustration in the succeeding section.\n",
    "\n",
    "We can generalize the above by considering $k$ neighbors such that the target of a given feature {$x_q^a$, $x_q^b$, $\\dots$, $x_q^M$} is:    \n",
    "1. the **mode** of the state ${y_i}$ based on the k-th nearest neighbor (collection of $k$ smallest euclidean distances $d_q^i$) and,   \n",
    "2. in case of a tied number of states, the *state with the highest population* in  the training set is prioritized. If population is equal, then the *state that appears first* in the training set is prioritized. Note that these are arbitrary rules in `sklearn`.\n",
    "\n",
    "The number of nearest neighbors is coded as `n_neighbors` in Python's `scikit-learn` library and is the most critical parameter for a kNN-based classifier.                     \n",
    "\n",
    "In general, the distance is computed using Minkowski distance given by:\n",
    "\n",
    "\\begin{equation}\n",
    "d_q= \\left(\\left|(x_i^a-x_q^a)^p + (x_i^b-x_q^b)^p + \\ldots + (x_i^M-x_q^M)^p \\right| \\right)^{1/p}\n",
    "\\end{equation}\n",
    "\n",
    "where $d_q$ is known as Manhattan for $p=1$, Euclidean for $p=2$ (default), and Chebyshev distance for $p \\rightarrow \\infty$.    \n",
    "\n",
    "To know more about how distances are typically calculated, here is an excellent and concise reference: https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vM2yrveKTqqO"
   },
   "source": [
    "## Illustration\n",
    "\n",
    "To visually illustrate kNN let's use an example of a synthetic two-class classification dataset, the forge dataset, which has two features. The data set available in the $mglearn$ library, you have the list of two features each for sample $i$ given by {$X_i$}={$x_i^a, x_i^b$} and the list of the corresponding $y_i$. Below is a scatter plot visualizing all of the data points in this dataset. The plot has the first feature on the x-axis and the second feature on the y-axis.\n",
    "\n",
    "As is always the case in in scatter plots, each data point is represented as one dot. The color of the dot indicates its class, with <font color='red'>red/orange</font> meaning class <font color='red'> 0 </font> and <font color='blue'>blue </font> meaning class <font color='blue'>1</font>. Unfortunately $mglearn$ is not part of the standard python packages in Google Colab hence we first need to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8740,
     "status": "ok",
     "timestamp": 1712824504909,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "UW4hzpO_53A4",
    "outputId": "d33c6bf0-63d8-44b2-81de-c97340473599"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade joblib==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7521,
     "status": "ok",
     "timestamp": 1712824512420,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "susSBVLWTv-h",
    "outputId": "6c0087b8-4c22-4e67-fa1d-485146ad596c"
   },
   "outputs": [],
   "source": [
    "!pip install mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QjmKDrQgTqqQ"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import mglearn #library provided by amueller\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1712824514639,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "EDhwm4_TTqqR",
    "outputId": "988ec2e7-b07c-4699-de6a-d4391eaafc51"
   },
   "outputs": [],
   "source": [
    "# generate dataset\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "\n",
    "print(\"Data Set:{}\".format(mglearn.datasets.make_forge()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1712824514639,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "jgSQF6XGTqqS",
    "outputId": "8c0b8946-cf50-42ce-8b2e-6cbd2eaca220"
   },
   "outputs": [],
   "source": [
    "print(\"The element of the first feature is given by: {}\".format(X[:, 0]))\n",
    "print(\"The element of the second feature is given by: {}\".format(X[:, 1]))\n",
    "print(\"The element of the target feature is given by: {}\".format(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "executionInfo": {
     "elapsed": 750,
     "status": "ok",
     "timestamp": 1712824515387,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "IcFwvyktTqqS",
    "outputId": "f6c4446d-192f-4146-ecf6-bc76c3794f04"
   },
   "outputs": [],
   "source": [
    "#plot dataset\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.legend([\"Class 0\", \"Class 1\"], loc=4)\n",
    "plt.xlabel(\"First feature $x_1$\")\n",
    "plt.ylabel(\"Second feature $x_2$\")\n",
    "print(\"X.shape: {}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuKYJwICTqqS"
   },
   "source": [
    "As you can see from X.shape, this dataset consists of 26 data points, with 2 features. The k-Nearest Neighbors (kNN) algorithm is arguably the simplest machine learning algorithm. Building the model only consists of storing the training dataset. To make a prediction for a new data point, the algorithm finds the closest data points in the training dataset, its “nearest neighbors”.\n",
    "\n",
    "In its simplest version, the algorithm only considers exactly one nearest neighbor, which is the closest training data point to the point we want to make a prediction for.\n",
    "\n",
    "The prediction is then simply the known output for this training point. Figure forge_one_neighbor illustrates this for the case of classification on the forge dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 787,
     "status": "ok",
     "timestamp": 1712824516172,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "9fgwQ-cETqqT",
    "outputId": "a608f566-7e85-45dc-d042-1b634dd72cd0"
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_classification(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDKf7sL1TqqT"
   },
   "source": [
    "Here, we added three new data points, shown as crosses. For each of them, we marked the closest point in the training set. The prediction of the one-nearest neighbor algorithm is the label of that point (shown by the color of the star).\n",
    "\n",
    "Instead of considering only the closest neighbor, we can also consider an arbitrary number $k$ of neighbors. This is where the name of the $k$ neighbors algorithm comes from. When considering more than one neighbor, we use voting to assign a label.\n",
    "\n",
    "This means, for each test point, we count how many neighbors are red, and how many neighbors are blue. We then assign the class that is more frequent: in other words, the majority class among the $k$ neighbors.\n",
    "\n",
    "Below is an illustration using the three closest neighbors. Again, the prediction is shown as the color of the cross. You can see that the prediction changed for the point in the top left from using only one neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1712824516172,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "O0eZcPGRTqqT",
    "outputId": "6787b4e2-b49f-4d9c-c47a-ff831c6ca3ec"
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_classification(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1712824516940,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "W4cT2oMBTqqU",
    "outputId": "58a9af99-c28c-4266-8ecf-9a92ef8aad9e"
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_classification(n_neighbors=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkj054RGTqqU"
   },
   "source": [
    "While this illustration is for a binary classification problem, you can imagine this working with any number of classes. For more classes, we count how many neighbors belong to each class, and again predict the most common class.\n",
    "\n",
    "Now let’s look at how we can apply the $k$ nearest neighbors algorithm using `scikit-learn`. First, we split our data into a training and a test set, so we can evaluate generalization performance, default is 75:25. This will be expounded again in our Example 1 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDeR3i6STqqU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = mglearn.datasets.make_forge() #Here is the data, we can get this from excel sheet or SQL\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0) #split into train =75%, test =25%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQMNb7FgTqqV"
   },
   "source": [
    "Next we import and instantiate the class. This is when we can set parameters, like the\n",
    "number of neighbors to use. Here, we set it to three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XaHn5Z4QTqqV"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3) #Parameter for kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCgktWXqTqqV"
   },
   "source": [
    "Now, we fit the classifier using the training set. For `KNeighborsClassifier` this means storing the dataset, so we can compute neighbors during prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1712824516940,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "pLxAjhoQTqqV",
    "outputId": "1725cd52-b020-459e-c1e1-6b7667ce8cdf"
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train) #Fit the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaLHO5C8TqqW"
   },
   "source": [
    "To make predictions on the test data, we call the predict method. This computes the\n",
    "nearest neighbors in the training set and finds the most common class among these. Let's look at the test set first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1712824516940,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "4YrppsRQIanG",
    "outputId": "8a37439e-69ee-4278-a5d5-fe1b6ed9819b"
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712824516940,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "wZeeadhNTqqW",
    "outputId": "e2c7b0a0-71e4-48cd-efc5-806b1c5adf38"
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1712824516940,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "0eOl-DrVTqqW",
    "outputId": "f474f56d-1d18-429d-977d-46788b99910c"
   },
   "outputs": [],
   "source": [
    "print(\"Test set predictions: {}\".format(clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyK3klJgTqqW"
   },
   "source": [
    "To evaluate how well our model generalizes, we can call the score method with the\n",
    "test data together with the test labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1712824516940,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "L2hnO65RTqqW",
    "outputId": "27fc1d23-7f03-438b-cfc8-5a4d7daea41c"
   },
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=10)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Train set accuracy: {:.2f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"Test set accuracy: {:.2f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8g_cR9hUTqqX"
   },
   "source": [
    "We see that our model is about 86% accurate, meaning the model predicted the class correctly for 86% of the samples in the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2Ef-JPvTqqX"
   },
   "source": [
    "## Analyzing kNN Classifier\n",
    "\n",
    "For two-dimensional datasets, we can also illustrate the prediction for all possible test point in the xy-plane. We color the plane red in regions where points would be assigned the red class, and blue otherwise. This lets us view the decision boundary, which is the divide between where the algorithm assigns class red versus where it\n",
    "assigns class blue.\n",
    "\n",
    "Here is a visualization of the decision boundary for one, three and five neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "executionInfo": {
     "elapsed": 2957,
     "status": "ok",
     "timestamp": 1712824519894,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "acGhxu07TqqX",
    "outputId": "a17b1b2d-e7a3-40e2-e173-ddb533783652",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "\n",
    "for n_neighbors, ax in zip([1, 5, 10], axes):\n",
    "    # the fit method returns the object self, so we can instantiate\n",
    "    # and fit in one line:\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X, y)\n",
    "    mglearn.plots.plot_2d_separator(clf, X, fill=True, eps=0.5, ax=ax, alpha=.4)\n",
    "    mglearn.discrete_scatter(X[:, 0], X[:, 1], y, ax=ax)\n",
    "    ax.set_title(\"{} neighbor(s)\".format(n_neighbors))\n",
    "    ax.set_xlabel(\"feature 1\")\n",
    "    ax.set_ylabel(\"feature 2\")\n",
    "axes[0].legend(loc=3)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjmgHlqeTqqX"
   },
   "source": [
    "As you can see in the left figure, using a single neighbor results in a decision boundary\n",
    "that follows the training data closely. Considering more and more neighbors leads\n",
    "to a smoother decision boundary. A smoother boundary corresponds to a simple\n",
    "model.     \n",
    "\n",
    "**In other words, using fewer neighbors corresponds to higher model complexity (as shown on the right side of Figure `model_complexity`), and using many neighbors corresponds to lower model complexity.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1712824519894,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "qbQ5S9QRTqqY",
    "outputId": "21346095-2020-46b8-94cd-12d5fd23f35b"
   },
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.make_forge()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40,random_state=1)\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 15\n",
    "neighbors_settings = range(1, 15)\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "\n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rt2kAEU1OQkV"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## ⚠️ Checkpoint ⚠️\n",
    "\n",
    "In the next 5-10 minutes, discuss these concepts with your LT to check your understanding:\n",
    "1. What is the difference between **Classification** and **Regression**?\n",
    "2. How does kNN work?\n",
    "3. What is the primary hyperparameter of kNN?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCOgEo3dTqqY"
   },
   "source": [
    "# Example 1. Iris Flower Classification\n",
    "---\n",
    "\n",
    "Let’s assume that a hobby botanist is interested in distinguishing what the species is of\n",
    "some iris flowers that she found. She has collected some measurements associated\n",
    "with the iris: the length and width of the petals, and the length and width of the sepal,\n",
    "all measured in centimeters.\n",
    "\n",
    "She also has the measurements of some irises that have been previously identified by\n",
    "an expert botanist as belonging to the species Setosa, Versicolor or Virginica. For\n",
    "these measurements, she can be certain of which species each iris belongs to. Let’s\n",
    "assume that these are the only species our hobby botanist will encounter in the wild.\n",
    "Our goal is to build a machine learning model that can learn from the measurements\n",
    "of these irises whose species is known, so that we can predict the species for a new\n",
    "iris.\n",
    "\n",
    "![Iris](https://user-images.githubusercontent.com/25600601/114910229-36450f80-9e50-11eb-9df8-4dfe8e17b936.png)\n",
    "https://morioh.com/p/eafb28ccf4e3\n",
    "\n",
    "Since we have measurements for which we know the correct species of iris, this is a\n",
    "supervised learning problem. In this problem, we want to predict one of several\n",
    "options (the species of iris). This is an example of a classification problem. The possible\n",
    "outputs (different species of irises) are called classes.\n",
    "Since every iris in the dataset belongs to one of three classes this problem is a threeclass\n",
    "classification problem.\n",
    "\n",
    "The desired output for a single data point (an iris) is the species of this flower. For a\n",
    "particular data point, the species it belongs to is called its label.\n",
    "\n",
    "**Meet the data**\n",
    "\n",
    "The data we will use for this example is the iris dataset, a classical dataset in machine\n",
    "learning an statistics.\n",
    "It is included in scikit-learn in the dataset module. We can load it by calling the\n",
    "load_iris function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VAFDepZ3TqqY"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1712824519895,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "Tp0wwGwzTqqY",
    "outputId": "d1fba92f-9c40-412e-b5c8-9d13bf326f0b"
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(iris_dataset['data']) #Feature variables\n",
    "df.columns=iris_dataset['feature_names'] #ADD the feature_names as column labels\n",
    "df['Target'] = iris_dataset['target'] #ADD the target as another column\n",
    "df #DISPLAY the first five rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKuQyiBHTqqZ"
   },
   "source": [
    "We see that the data contains measurements for 150 different flowers.\n",
    "Remember that the individual items are called **samples** in machine learning, and their\n",
    "properties are called **features**.  The **shape** of the data array is the number of samples times the number of features.\n",
    "\n",
    "This is a convention in $sklearn$ (scikit-learn), and your data will always be assumed to be in this shape.\n",
    "\n",
    "Here are the feature values for the first five samples:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xXIdknKTqqZ"
   },
   "source": [
    "From this data, we can see that all of the first ten flowers have a petal width of 0.1 to 0.4 cm and that the sixth flower has the longest sepal, at 5.4 cm. The target array contains the species of each of the flowers that were measured. The target is a one-dimensional array, with one entry per flower. The meaning of the numbers are given by the iris['target_names'] array:  \n",
    "   \n",
    "0 means *Setosa*,     \n",
    "1 means *Versicolor*, and     \n",
    "2 means *Virginica*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w52k6rlZTqqa"
   },
   "source": [
    "### Measuring Success: Training and Testing Data\n",
    "\n",
    "We want to build a machine learning model from this data that can predict the species\n",
    "of iris for a new set of measurements. Before we can apply our model to new measurements, we need to know whether our model actually works, that is whether we should trust its predictions.\n",
    "\n",
    "Unfortunately, we can not use the data we use to build the model to evaluate it. This is\n",
    "because our model can always simply remember the whole training set, and will\n",
    "therefore always predict the correct label for any point in the training set. This\n",
    "“remembering” does not indicate to us whether our model will generalize well, in\n",
    "other words whether it will also perform well on new data. So before we apply our\n",
    "model to new measurements, we will want to know whether we can trust its predictions.\n",
    "To assess the models’ performance, we show the model new data (that it hasn’t seen\n",
    "before) for which we have labels. This is usually done by splitting the labeled data we\n",
    "have collected (here our 150 flower measurements) into two parts.\n",
    "The part of the data is used to build our machine learning model, and is called the\n",
    "training data or training set. The rest of the data will be used to access how well the\n",
    "model works and is called test data, test set or hold-out set.\n",
    "Scikit-learn contains a function that shuffles the dataset and splits it for you, the\n",
    "train_test_split function.\n",
    "\n",
    "This function extracts 75% of the rows in the data as the training set, together with\n",
    "the corresponding labels for this data. The remaining 25% of the data, together with\n",
    "the remaining labels are declared as the test set.\n",
    "How much data you want to put into the training and the test set respectively is\n",
    "somewhat arbitrary, but using a test-set containing 25% of the data is a good rule of\n",
    "thumb.\n",
    "In scikit-learn, data is usually denoted with a capital X, while labels are denoted by a\n",
    "lower-case y.\n",
    "Let’s call train_test_split on our data and assign the outputs using this nomenclature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7NCXB8oTqqa"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'],test_size=0.25,\n",
    "random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3hb5CLgTqqa"
   },
   "source": [
    "The train_test_split function shuffles the dataset using a pseudo random number generator before making the split. If we would take the last 25% of the data as a test set, all the data point would have the label 2, as the data points are sorted by the label (see the output for iris['target'] above). Using a tests set containing only one of\n",
    "the three classes would not tell us much about how well we generalize, so we shuffle our data, to make sure the test data contains data from all classes.\n",
    "\n",
    "To make sure that we will get the same output if we run the same function several times, we provide the pseudo random number generator with a fixed seed using the random_state parameter. This will make the outcome deterministic, so this line will always have the same outcome. We will always fix the random_state in this way when using randomized procedures.\n",
    "\n",
    "The output of the train_test_split function are X_train, X_test, y_train and y_test, which are all numpy arrays. X_train contains 75% of the rows of the dataset, and X_test contains the remaining 25%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 561,
     "status": "ok",
     "timestamp": 1712824520449,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "KXYcTYVgTqqa",
    "outputId": "d43da1b3-731a-43f2-845e-3fc25ea753bc"
   },
   "outputs": [],
   "source": [
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"Y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1712824520449,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "CexNAKoOTqqa",
    "outputId": "34cc42e5-878a-4428-ed28-8d1b8ff62628"
   },
   "outputs": [],
   "source": [
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"Y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_hVnhiDTqqb"
   },
   "source": [
    "### Pair Plot: A first look at the data\n",
    "\n",
    "Before building a machine learning model, it is often a good idea to inspect the data,\n",
    "to see if the task is easily solvable without machine learning, or if the desired information\n",
    "might not be contained in the data.\n",
    "\n",
    "Additionally, inspecting your data is a good way to find abnormalities and peculiarities.\n",
    "Maybe some of your irises were measured using inches and not centimeters, for\n",
    "example. In the real world, inconsistencies in the data and unexpected measurements\n",
    "are very common.\n",
    "\n",
    "One of the best ways to inspect data is to visualize it. One way to do this is by using a\n",
    "scatter plot. A scatter plot of the data puts one feature along the x-axis, one feature along the yaxis,\n",
    "and draws a dot for each data point.\n",
    "Unfortunately, computer screens have only two dimensions, which allows us to only\n",
    "plot two (or maybe three) features at a time. It is difficult to plot datasets with more\n",
    "than three features this way.\n",
    "One way around this problem is to do a pair plot, which looks at all pairs of two features.\n",
    "If you have a small number of features, such as the four we have here, this is\n",
    "quite reasonable. You should keep in mind that a pair plot does not show the interaction\n",
    "of all of features at once, so some interesting aspects of the data may not be\n",
    "revealed when visualizing it this way.\n",
    "Here is a pair plot of the features in the training set. The data points are colored\n",
    "according to the species the iris belongs to.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 8536,
     "status": "ok",
     "timestamp": 1712824528984,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "xK5wJMv2Tqqb",
    "outputId": "c2e11bf4-2f09-4c68-a705-7631201e3b6d"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\") #whitegrid, ticks  #df = sns.load_dataset(\"iris\")\n",
    "df=pd.DataFrame.from_dict(iris_dataset['data']) #Feature variables\n",
    "df.columns=iris_dataset['feature_names'] #ADD the feature_names as column labels\n",
    "df['Target'] = iris_dataset['target'] #ADD the target as another column\n",
    "#df.head(10) #DISPLAY the first ten rows   #df=iris_dataset\n",
    "sns.pairplot(df, hue=\"Target\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "T0TNvdDhTqqb",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Building this model only consists of storing the training set. To make a prediction for a new data point, the algorithm finds the point in the training set that is closest to the new point. Then, it and assigns the label of this closest data training point to the new data point.\n",
    "\n",
    "All machine learning models in scikit-learn are implemented in their own class, which are called Estimator classes. The k nearest neighbors classification algorithm is implemented in the KNeighborsClassifier class in the neighbors module. Before we can use the model, we need to instantiate the class into an object. This is\n",
    "when we will set any parameters of the model. The single parameter of the *KNeighborsClassifier* is the number of neighbors, which we will set to one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glyLxBf0Tqqb"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_PDxZpiTqqc"
   },
   "source": [
    "The knn object encapsulates the algorithm to build the model from the training data,\n",
    "as well the algorithm to make predictions on new data points.\n",
    "It will also hold the information the algorithm has extracted from the training data.\n",
    "In the case of KNeighborsClassifier, it will just store the training set.\n",
    "To build the model on the training set, we call the fit method of the knn object,\n",
    "which takes as arguments the numpy array X_train containing the training data and\n",
    "the numpy array y_train of the corresponding training labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1712824528984,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "7yiw7irpTqqc",
    "outputId": "1cce3c92-0016-4193-9144-4e3052576590"
   },
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gQD-ujOTqqc"
   },
   "source": [
    "### Making predictions\n",
    "We can now make predictions using this model on new data, for which we might not\n",
    "know the correct labels.\n",
    "\n",
    "Imagine we found an iris in the wild with a sepal length of 5cm, a sepal width of\n",
    "2.9cm, a petal length of 1cm and a petal width of 0.2cm. What species of iris would\n",
    "this be?\n",
    "\n",
    "We can put this data into a numpy array, again with the shape number of samples\n",
    "(one) times number of features (four):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1712824528984,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "N2cZTEeJTqqc",
    "outputId": "03becb0a-0421-4a44-fb68-c1d54058c7f4"
   },
   "outputs": [],
   "source": [
    "X_new = np.array([[5, 2.9, 8, 0.2]])\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZujyBO2Tqqc"
   },
   "source": [
    "To make prediction we call the predict method of the knn object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1712824528984,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "bthyB5_hTqqc",
    "outputId": "4bd26d52-b723-420b-fcb7-6ca1979c7523"
   },
   "outputs": [],
   "source": [
    "prediction = knn.predict(X_new)\n",
    "print(\"Prediction: {}\".format(prediction))\n",
    "print(\"Predicted target name: {}\".format(\n",
    "       iris_dataset['target_names'][prediction]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7xFvtxgTqqd"
   },
   "source": [
    "Our model predicts that this new iris belongs to the class 2, meaning its species is\n",
    "Virginica.\n",
    "But how do we know whether we can trust our model? We don’t know the correct\n",
    "species of this sample, which is the the whole point of building the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeCLbhsxTqqd"
   },
   "source": [
    "### Evaluating the model\n",
    "\n",
    "This is where the test set that we created earlier comes in. This data was not used to\n",
    "build the model, but we do know what the correct species are for each iris in the test\n",
    "set.\n",
    "We can make a prediction for an iris in the test data, and compare it against its label\n",
    "(the known species). We can measure how well the model works by computing the\n",
    "accuracy, which is the fraction of flowers for which the right species was predicted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712824528984,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "ao0WhW2FTqqd",
    "outputId": "933b557f-c22c-451b-e77b-bc98231bcef0"
   },
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1712824528984,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "dNk-fsIUTqqd",
    "outputId": "25531605-15df-438a-833a-2a7da126ef78"
   },
   "outputs": [],
   "source": [
    "print(\"Test set score: {:.2f}\".format(np.mean(y_pred == y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThQV2EKoTqqd"
   },
   "source": [
    "We can also use the score method of the knn object, which will compute the test set\n",
    "accuracy for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1712824528984,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "JTPa_IQ8Tqqd",
    "outputId": "ddcda11f-9f31-4e10-cdc3-b57fb0e17328"
   },
   "outputs": [],
   "source": [
    "print(\"Test set score: {:.2f}\".format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrnjzYfTTqqe"
   },
   "source": [
    "For this model, the test set accuracy is about 0.97, which means we made the right\n",
    "prediction for 97% of the irises in the test set. Under some mathematical assumptions,\n",
    "this means that we can expect our model to be correct 97% of the time for new\n",
    "irises.\n",
    "For our hobby botanist application, this high level of accuracy means that our models\n",
    "may be trustworthy enough to use. In later chapters we will discuss how we can\n",
    "improve performance, and what caveats there are in tuning a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 741,
     "status": "ok",
     "timestamp": 1712824529722,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "WUq_CUz4Tqqe",
    "outputId": "fce5386d-8548-454d-bd4c-aa6eb5daa98b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], test_size=0.25,\n",
    "random_state=143)\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 10\n",
    "neighbors_settings = range(1, 50)\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "\n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObGICGRD-TjO"
   },
   "source": [
    "Let's run 50 trials to see the real trend of Accuracy as a function of n_neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q27dq0cY-OXc"
   },
   "outputs": [],
   "source": [
    "lahat_training = pd.DataFrame()\n",
    "lahat_test = pd.DataFrame()\n",
    "for seedN in range(1, 50, 1):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], test_size=0.25,random_state=seedN)\n",
    "\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    neighbors_settings = range(1, 50) # try n_neighbors from 1 to 50\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        clf = KNeighborsClassifier(n_neighbors=n_neighbors)  # build the model\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        training_accuracy.append(clf.score(X_train, y_train)) # record training set accuracy\n",
    "        test_accuracy.append(clf.score(X_test, y_test))   # record generalization accuracy\n",
    "\n",
    "    lahat_training[seedN] = training_accuracy\n",
    "    lahat_test[seedN] = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "executionInfo": {
     "elapsed": 887,
     "status": "ok",
     "timestamp": 1712824563456,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "MHZ0qK8D-Srg",
    "outputId": "844b9aea-61b8-4998-808c-e71655e4ee2a"
   },
   "outputs": [],
   "source": [
    "plt.errorbar(neighbors_settings, lahat_training.mean(axis=1),\n",
    "             yerr=lahat_training.std(axis=1)/2, label=\"training accuracy\")\n",
    "plt.errorbar(neighbors_settings, lahat_test.mean(axis=1),\n",
    "             yerr=lahat_test.std(axis=1)/6, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCAZeFRtTqqe"
   },
   "source": [
    "### Summary\n",
    "Let's summarize what we learned in this example.\n",
    "\n",
    "- <u>Step 1: Start with the question</u>. We started off formulating a task of\n",
    "predicting which species of iris a particular flower belongs to by using physical measurements\n",
    "of the flower.\n",
    "\n",
    "- <u>Step 2: Prepare Data</u>. We used a dataset of measurements that was annotated by an expert with the correct species to build our model, making this a supervised learning task. There were three possible species, Setosa, Versicolor or Virginica, which made the task a three-class classification problem. The possible species are called classes in the classification problem, and the species of a single iris is called its label. The dataset consists of two numpy arrays, one containing the data, which is referred to as X in scikit-learn, and one containing the correct or desired outputs, which is called y. The array X is a two-dimensional array of features, with one row per data point, and one column per feature. The array y is a one-dimensional array, which here contained one class label from 0 to 2 for each of the samples. We split our dataset into a training set, to build our model, and a test set, to evaluate how well our model will generalize to new, unseen data.\n",
    "\n",
    "- <u>Step 3: Tune the model parameters</u>. We chose the k nearest neighbors classification algorithm, which makes predictions\n",
    "for a new data point by considering its closest neighbor(s) in the training set. The algorithm is implemented in the `KNeighborsClassifier` class, which contains the algorithm to build the model, as well as the algorithm to make a prediction using the model. We instantiated the class, setting parameters. Then, we built the model by calling the fit method, passing the training data X_train and training outputs y_train as parameters.\n",
    "\n",
    "- <u>Step 4: Evaluate the model</u>. We evaluated the model using the score method, that computes the accuracy of the\n",
    "model. We applied the score method to the test set data and the test set labels, and found that our model is about 97% accurate, meaning it is correct 97% of the time on the test set. This gave us the confidence to apply the model to new data (in our example, new flower measurements), and trust that the model will be correct about 97% of the time.\n",
    "\n",
    "**Here is a summary of the code needed for the whole training and evaluation procedure:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1712824563457,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "juzxqNIiTqqe",
    "outputId": "2ac49476-807b-4478-c37d-b8f825397bcf"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_dataset['data'], iris_dataset['target'], random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test set score: {:.2f}\".format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ia_kBtoTqqe"
   },
   "source": [
    "This snippet contains the core code for applying any machine learning algorithms using scikit-learn. The fit, predict and score methods are the common interface to supervised models in *sklearn* (scikit-learn), and with the concepts introduced in this chapter, you can apply these models to many machine learning tasks.\n",
    "\n",
    "In the next chapter, we will go into more depth about the different kinds of supervised models in scikit-learn, and how to apply them successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sFQfnYvQNyy"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## ⚠️ Checkpoint ⚠️\n",
    "\n",
    "The above code snippet is critical. This is the general template you have whenever you want to run a basic machine learning model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "t0Zqz5HnTqqe",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Example 2. Boston Cancer Dataset\n",
    "---\n",
    "\n",
    "Wisconsin breast cancer dataset (or cancer for\n",
    "short, read `cancer.DESC` if you want to learn more), which records clinical measurements of breast cancer tumors. Each tumor is labeled as “benign” (for harmless tumors) or “malignant” (for cancerous tumors), and the task is to learn to predict whether a tumor is malignant based on the measurements of the tissue.\n",
    "\n",
    "The data can be loaded using the `load_breast_cancer` from scikit-learn. Datasets that are included in scikit-learn are usually stored as Bunch objects, which contain some information about the dataset as well as the actual data.\n",
    "\n",
    "All you need to know about Bunch objects is that they behave like dictionaries, with the added benefit that you can access values using a dot (as in `bunch.key` instead of\n",
    "`bunch['key']`).\n",
    "\n",
    "## Validation Sets\n",
    "Having a validation set is important in Machine Learning as it helps us prevent overfitting. We will discuss this in more detail in later lecture on **Model Evaluation**.\n",
    "\n",
    "1. **3-way Split**: Involves three separate sets for training, validation, and testing. It is useful when there is a sufficient amount of data, and the validation set is needed to tune the model's hyperparameters.\n",
    "2. **Cross-validation**: Does not have a separate validation set; instead, it repeatedly splits the data into training and testing sets. It is useful when the dataset is limited, as it allows for a more robust estimation of the model's performance. Here we cover two types of cross-validation methods that are commonly used: **Monte Carlo** and **k-fold**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1712824563457,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "TfVPrwyPTqqf",
    "outputId": "581053dd-ac8c-44a6-9a47-22042e03ea0a"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer_dataset = load_breast_cancer()\n",
    "print(\"cancer.keys():\\n{}\".format(cancer_dataset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1712824563457,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "NEeJLqUxTqqf",
    "outputId": "32a2a930-ae8c-46d8-dded-955004d15def"
   },
   "outputs": [],
   "source": [
    "print(\"cancer.DESCR:\\n{}\".format(cancer_dataset.DESCR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1712824563457,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "bGttzu4sTqqf",
    "outputId": "92b680f7-46c7-4252-b678-b4ee66ea5b08"
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(cancer_dataset['data']) #Feature variables\n",
    "df.columns=cancer_dataset['feature_names'] #ADD the feature_names as column labels\n",
    "df['Target'] = cancer_dataset['target'] #ADD the target as another column\n",
    "df.head(-10) #DISPLAY the first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Iqe9RiNTqqf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_dataset['data'], cancer_dataset['target'],test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1712824563457,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "j9ESFFWETqqf",
    "outputId": "cbbd213a-8d1b-41b3-de22-21d402eaf152"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1712824563457,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "f8eQEgBKTqqf",
    "outputId": "ae06f89c-493a-4214-97b6-0060409b8a14"
   },
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(\"Test set score: {:.2f}\".format(np.mean(y_pred == y_test)))\n",
    "\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))\n",
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1712824563458,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "8VNdq9O_Tqqg",
    "outputId": "a46cd950-b8fd-426a-d63f-500064c1cfa5"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer_dataset['data'],cancer_dataset['target'],\n",
    "                                                    test_size=0.25,random_state=20)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(X_train, y_train) #decision boundaries stored here\n",
    "\n",
    "print(\"train accuracy= \", knn.score(X_train, y_train))\n",
    "print(\"test accuracy =\", knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 2995,
     "status": "ok",
     "timestamp": 1712824566447,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "amNiFAe5Tqqg",
    "outputId": "94ee2bfc-d63a-4138-c13d-ec9c96f42124"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_dataset['data'],cancer_dataset['target'],\n",
    "                                                    test_size=0.25,random_state=20)\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 10\n",
    "neighbors_settings = range(1, 50)\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "\n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tueGSgMBxMD-"
   },
   "source": [
    "### **Method 1:** Monte Carlo Cross Validation (MCCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bZ6XHV6j29J"
   },
   "outputs": [],
   "source": [
    "lahat_training = pd.DataFrame()\n",
    "lahat_test = pd.DataFrame()\n",
    "for seedN in range(1, 50, 1):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(cancer_dataset['data'],cancer_dataset['target'],\n",
    "                                                        test_size=0.25, random_state=seedN)\n",
    "\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    neighbors_settings = range(1, 50) # try n_neighbors from 1 to 50\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        clf = KNeighborsClassifier(n_neighbors=n_neighbors)  # build the model\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        training_accuracy.append(clf.score(X_train, y_train)) # record training set accuracy\n",
    "        test_accuracy.append(clf.score(X_test, y_test))   # record generalization accuracy\n",
    "\n",
    "    lahat_training[seedN]=training_accuracy\n",
    "    lahat_test[seedN] = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "executionInfo": {
     "elapsed": 757,
     "status": "ok",
     "timestamp": 1712824697586,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "rPG4yyHdj9wc",
    "outputId": "221843eb-2c38-4121-b078-463c21dfaf0f"
   },
   "outputs": [],
   "source": [
    "plt.errorbar(neighbors_settings, lahat_training.mean(axis=1),\n",
    "             yerr=lahat_training.std(axis=1)/2, label=\"training accuracy\")\n",
    "plt.errorbar(neighbors_settings, lahat_test.mean(axis=1),\n",
    "             yerr=lahat_test.std(axis=1)/6, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ql-Dd-vexjnx"
   },
   "source": [
    "Based on these results, one would choose the following hyperparameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712824697586,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "vP5oOL--yBhl",
    "outputId": "fb6bd9c0-e37f-4c4a-b266-43fc06e70f02"
   },
   "outputs": [],
   "source": [
    "print(\"Best test set mean accuracy: {:.2f}%\".format(lahat_test.mean(axis = 1).max() * 100))\n",
    "print(\"For k = {}\".format(lahat_test.mean(axis = 1).argmax() + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRoVtUuSmSsr"
   },
   "source": [
    "### **Method 2:** 3-way Split\n",
    "Illustration of the 60-20-20 **train/validation/test** split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1712824697586,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "QVcaLD4anqNz",
    "outputId": "258b10e8-20b8-4c6b-8a23-c10b5f691738"
   },
   "outputs": [],
   "source": [
    "# Split the data into a training set (80%) and a test set (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_dataset['data'], cancer_dataset['target'], test_size=0.2, random_state=1337)\n",
    "\n",
    "# Split the training set into a training set (60%) and a validation set (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1337)\n",
    "\n",
    "# Sanity check: dimensionality of dataset splits\n",
    "print(\"Complete dataset: {}\".format(cancer_dataset['data'].shape))\n",
    "print(\"Training set: {}\".format(X_train.shape))\n",
    "print(\"Validation set: {}\".format(X_val.shape))\n",
    "print(\"Test set: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UI3omzklpeyY"
   },
   "source": [
    "Now let us apply this over several trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPwW5eXVm5vy"
   },
   "outputs": [],
   "source": [
    "lahat_training = pd.DataFrame()\n",
    "lahat_val = pd.DataFrame()\n",
    "lahat_test = pd.DataFrame()\n",
    "\n",
    "for seedN in range(1, 50, 1):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # Split the data into a training set (80%) and a test set (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(cancer_dataset['data'], cancer_dataset['target'], test_size=0.2, random_state=seedN)\n",
    "\n",
    "    # Split the training set into a training set (60%) and a validation set (20%)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=seedN)\n",
    "\n",
    "    training_accuracy = []\n",
    "    val_accuracy = []\n",
    "    test_accuracy = []\n",
    "    neighbors_settings = range(1, 50) # try n_neighbors from 1 to 50\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        clf = KNeighborsClassifier(n_neighbors=n_neighbors)  # build the model\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        training_accuracy.append(clf.score(X_train, y_train)) # record training set accuracy\n",
    "        val_accuracy.append(clf.score(X_val, y_val)) # record validation set accuracy\n",
    "        test_accuracy.append(clf.score(X_test, y_test)) # record generalization accuracy\n",
    "\n",
    "    lahat_training[seedN] = training_accuracy\n",
    "    lahat_val[seedN] = val_accuracy\n",
    "    lahat_test[seedN] = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1712824832958,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "z46sQ8aOpzyC",
    "outputId": "f311d236-f800-400b-a751-d1d16959c60f"
   },
   "outputs": [],
   "source": [
    "plt.errorbar(neighbors_settings, lahat_training.mean(axis=1),\n",
    "             yerr=lahat_training.std(axis=1)/2, label=\"training accuracy\", alpha = 0.8)\n",
    "plt.errorbar(neighbors_settings, lahat_test.mean(axis=1),\n",
    "             yerr=lahat_test.std(axis=1)/6, label=\"test accuracy\", alpha = 0.8)\n",
    "plt.errorbar(neighbors_settings, lahat_val.mean(axis=1),\n",
    "             yerr=lahat_val.std(axis=1)/6, label=\"validation accuracy\", alpha = 0.8)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kc4Hrrv3zIHg"
   },
   "source": [
    "Based on these results, one would choose the following hyperparameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712824832958,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "VYqgtWfmzKLy",
    "outputId": "b9bda259-2a8e-4a07-f7b4-5636dc71cbf6"
   },
   "outputs": [],
   "source": [
    "best_val_k = lahat_val.mean(axis = 1).argmax() + 1\n",
    "print(\"Best validation set mean accuracy: {:.2f}%\".format(lahat_val.mean(axis = 1).max() * 100))\n",
    "print(\"For k = {}\".format(best_val_k))\n",
    "print(\"Mean performance on test set of k = {}: {:.2f}%\".format(best_val_k, lahat_test.mean(axis = 1)[best_val_k] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1712824832958,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "G4GqAE1I0Zuo",
    "outputId": "69f7926a-6865-4b4c-fbea-538b944d9c9f"
   },
   "outputs": [],
   "source": [
    "print(\"Best test set mean accuracy: {:.2f}%\".format(lahat_test.mean(axis = 1).max() * 100))\n",
    "print(\"For k = {}\".format(lahat_test.mean(axis = 1).argmax() + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NDi9hp0mU_C"
   },
   "source": [
    "### **Method 3:** k-fold Cross-validation\n",
    "There is **no explicit validation set** in k-fold cross-validation.\n",
    "\n",
    "Compared to Method 0, cross-validation is more robust and provides a more reliable estimate of the model's performance as it ensures that **each data point is used for both training and testing**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0Wq1N6L1fJU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# we define k-fold Cross-validation with 10 folds\n",
    "number_folds = 10\n",
    "kf = KFold(n_splits=number_folds, shuffle=True, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-Rrz3nGmKla"
   },
   "outputs": [],
   "source": [
    "lahat_training = pd.DataFrame()\n",
    "lahat_test = pd.DataFrame()\n",
    "fold = 0\n",
    "\n",
    "X = cancer_dataset['data']\n",
    "y = cancer_dataset['target']\n",
    "\n",
    "# Compared to Method 0, this line is the only difference.\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    neighbors_settings = range(1, 50) # try n_neighbors from 1 to 50\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        clf = KNeighborsClassifier(n_neighbors=n_neighbors)  # build the model\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        training_accuracy.append(clf.score(X_train, y_train)) # record training set accuracy\n",
    "        test_accuracy.append(clf.score(X_test, y_test))   # record generalization accuracy\n",
    "\n",
    "    lahat_training[fold] = training_accuracy\n",
    "    lahat_test[fold] = test_accuracy\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1712824858456,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "3qxdNW7j3emB",
    "outputId": "cd1cc55a-1b7a-4f9d-cb2e-83bb9e70d565"
   },
   "outputs": [],
   "source": [
    "plt.errorbar(neighbors_settings, lahat_training.mean(axis=1),\n",
    "             yerr=lahat_training.std(axis=1)/2, label=\"training accuracy\")\n",
    "plt.errorbar(neighbors_settings, lahat_test.mean(axis=1),\n",
    "             yerr=lahat_test.std(axis=1)/8, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T68TIcOu1XA-"
   },
   "source": [
    "Based on these results, one would choose the following hyperparameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1712824858456,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "OhP2HFJu1Xq9",
    "outputId": "8fd6d7a9-1c0b-40a4-cbc3-fe4b7fc80c05"
   },
   "outputs": [],
   "source": [
    "print(\"Best test set mean accuracy: {:.2f}%\".format(lahat_test.mean(axis = 1).max() * 100))\n",
    "print(\"For k = {}\".format(lahat_test.mean(axis = 1).argmax() + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "781Pu4oKTqqg"
   },
   "source": [
    "# Example 3. University of the Philippines College Admission Test  (UPCAT) Prediction\n",
    "---\n",
    "\n",
    "Given here are actual class performance of 100 students of a school based in Metro Manila who took the UPCAT. UPCAT is the most competitive college entrance exam in the Philippines. Information contains the grades of each of the students in English, Math, Science together with their general weighted averages from grades 7-9. An IQ test conducted by the school is also made available together with a confidentially measured variable abbreviated as SA.  Explore how accurate can k-NN forecast UPCAT passers (pass=1, fail=0) and what is the optimal nearest-neighbor parameter. In 2020 due to the COVID 19 pandemic, UPCAT is changed to  UPCA as the \"Test\" is removed and the passing algorithm was derived solely on the grades and ``competitive index'' of the school.\n",
    "\n",
    "A. Make a scatter matrix of the features.\n",
    "\n",
    "B. Use kNN and comment on the optimal choice of **n_neighbors**.\n",
    "\n",
    "C. Tell a story about the system: predictability, value of the result(s), or any interesting ideas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqzeVRo7bHkD"
   },
   "source": [
    "### Load Data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CuwrmZpoUvHh"
   },
   "outputs": [],
   "source": [
    "data_dir = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 506,
     "status": "ok",
     "timestamp": 1712824861343,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "YApwFvk1Xb7U",
    "outputId": "f8c1f968-759d-414a-b73a-8295d2fb0a7a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 1276,
     "status": "ok",
     "timestamp": 1712824862618,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "LLpgL33oTqqg",
    "outputId": "31a776f1-8d9b-4790-8b9b-9c2ba4885703"
   },
   "outputs": [],
   "source": [
    "df_UPCAT = pd.read_excel(data_dir+'UPCAT_DATA2.xlsx', sheet_name=\"100\")\n",
    "dummy=df_UPCAT\n",
    "df_UPCAT.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1712824862619,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "aCSjFibHTqqh",
    "outputId": "8edc2a5a-cc5c-49ac-e451-e034770d3da4"
   },
   "outputs": [],
   "source": [
    "df_features=dummy.drop('Target', axis=1) #Remove the Target\n",
    "len(df_features)\n",
    "df_features.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1712824862619,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "zYzYNEuXTqqh",
    "outputId": "25166821-2881-41ed-a564-3042a1512261"
   },
   "outputs": [],
   "source": [
    "df_features.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1712824862619,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "1JOA3DehTqqh",
    "outputId": "31e9a322-3b3a-4d75-9483-aada0655a5e7"
   },
   "outputs": [],
   "source": [
    "df_UPCAT['Target'].head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6PeSJqxTqqh"
   },
   "source": [
    "### Proportional Chance Criterion (PCC)\n",
    "<u>Learning point</u>: How do you know your classifier is good enough? One way is to calculate the proportional chance criteria ($\\mathbf{P}_{CC}$). The $\\mathbf{P}_{CC}$ for $M$ possible states is given by:\n",
    "    \n",
    "\\begin{equation}\n",
    "\\mathbf{P}_{CC}= (\\frac{n_1}{N})^2 + (\\frac{n_2}{N})^2 + \\cdots + (\\frac{n_M}{N})^2  \n",
    "\\end{equation}\n",
    "\n",
    "where $n_M$ is the number of samples at state $M$. The $\\mathbf{P}_{CC}$ also referred to as the *proportional by chance accuracy rate* computes the highest possible random chance of classifying data without explicit mathematical model other than population counts. As a heuristic or rule of thumb, a classifier machine learning model is considered highly succcesful when the test accuracy exceeds 1.25$\\mathbf{P}_{CC}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1712824862996,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "qmcShM0vTqqh",
    "outputId": "2bd1d702-cd32-4941-b923-18a2f63ce7ce"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "state_counts = Counter(df_UPCAT['Target'])\n",
    "df_state = pd.DataFrame.from_dict(state_counts, orient='index')\n",
    "df_state.plot(kind='bar')\n",
    "\n",
    "num=(df_state[0]/df_state[0].sum())**2\n",
    "\n",
    "print(\"Population per class:{}\".format(df_state))\n",
    "\n",
    "print(\"Proportion Chance Criterion: {:0.2f}%\".format(100*num.sum()))\n",
    "print(\"1.25 * Proportion Chance Criterion: {:0.2f}%\".format(1.25*100*num.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1ckffAczXtRR6kElSc9O4diEXI4eDsPyE"
    },
    "executionInfo": {
     "elapsed": 99300,
     "status": "ok",
     "timestamp": 1712824962294,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "OINKTiaVTqqh",
    "outputId": "864d6f53-56fc-4b4c-f7e6-86e20b7a2eae"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "df = df_UPCAT\n",
    "sns.pairplot(df, hue=\"Target\")\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1712824962295,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "1rAewIwJTqqi",
    "outputId": "1074920e-3a8e-442c-9ae1-44f2260cae21"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features,df_UPCAT['Target'],\n",
    "                                                    test_size=0.25,random_state=42)\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "neighbors_settings = range(1, 50) # try n_neighbors from 1 to 50\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)  # build the model\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    training_accuracy.append(clf.score(X_train, y_train)) # record training set accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))   # record generalization accuracy\n",
    "\n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JtuvAstTqqi"
   },
   "source": [
    "Let's try to average over 50 different training and test set combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NuwbEKXTqqi"
   },
   "outputs": [],
   "source": [
    "lahat_training = pd.DataFrame()\n",
    "lahat_test = pd.DataFrame()\n",
    "for seedN in range(1,50,1):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_features,df_UPCAT['Target'],\n",
    "                                                        test_size=0.25, random_state=seedN)\n",
    "\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    neighbors_settings = range(1, 70) # try n_neighbors from 1 to 50\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        clf = KNeighborsClassifier(n_neighbors=n_neighbors)  # build the model\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        training_accuracy.append(clf.score(X_train, y_train)) # record training set accuracy\n",
    "        test_accuracy.append(clf.score(X_test, y_test))   # record generalization accuracy\n",
    "\n",
    "    lahat_training[seedN]=training_accuracy\n",
    "    lahat_test[seedN] = test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1712825024156,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "lHTWfYSncehx",
    "outputId": "61f86233-69df-4099-a873-c29db1703ab3"
   },
   "outputs": [],
   "source": [
    "plt.errorbar(neighbors_settings, lahat_training.mean(axis=1),\n",
    "             yerr=lahat_training.std(axis=1)/2, label=\"training accuracy\")\n",
    "plt.errorbar(neighbors_settings, lahat_test.mean(axis=1),\n",
    "             yerr=lahat_test.std(axis=1)/6, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1712825024156,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "BA0ANWi-cNTS",
    "outputId": "d65db198-b778-4282-e141-cec8939bb7da"
   },
   "outputs": [],
   "source": [
    "np.max(lahat_test.mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oz7hhfCjTqqi"
   },
   "source": [
    "Consider a new student. Let's see if he/she will pass the UPCAT entrance test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txZxrgSfTqqi"
   },
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=3)  # build the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "X_new = np.array([[77,82,86,94,87,92,84,80,92,1.4764,1.5045,1.4098,55,28]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1712825024156,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "B0BEAfp6Tqqj",
    "outputId": "679d17ef-430d-4f9a-fd94-799adde735d9"
   },
   "outputs": [],
   "source": [
    "prediction = clf.predict(X_new)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712825024156,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "dSo8_fpFTqqj",
    "outputId": "01d77095-513d-4775-8af2-8148d70d6f8e"
   },
   "outputs": [],
   "source": [
    "X_new = np.array([[55,52,55,57,53,51,57,62,51,2.6132,2.6818,2.7172,17,9]])\n",
    "prediction = clf.predict(X_new)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzV0UJM2Tqqj"
   },
   "source": [
    "# Appendices\n",
    "---\n",
    "\n",
    "For those who are interested to spend more time learning about coding and how to interact with excel data. We will not discuss the items below in class, but you may want to browse on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bhX1KC4j5sZ"
   },
   "source": [
    "## Appendix 1: Iris Dataset\n",
    "Some nice to learn programming notes. The iris object that is returned by load_iris is a Bunch object, which is very similar\n",
    "to a dictionary. It contains keys and values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 580,
     "status": "ok",
     "timestamp": 1712825024732,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "XbqsG67HTqqk",
    "outputId": "b11dd025-9900-43c8-ab96-fa5ae896e50e"
   },
   "outputs": [],
   "source": [
    "print(\"keys of iris_dataset: \\n{}\".format(iris_dataset.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XE82vJ_3Tqqk"
   },
   "source": [
    "The value to the key DESCR is a short description of the dataset. We show the beginning\n",
    "of the description here. Feel free to look up the rest yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1712825024732,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "VcDjPSbuTqqk",
    "outputId": "a869ce34-95d8-40a3-c40d-163600871ed7"
   },
   "outputs": [],
   "source": [
    "print(iris_dataset['DESCR'][:700] + \"\\n...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YTt-3DnTqqk"
   },
   "source": [
    "The value with key target_names is an array of strings, containing the species of\n",
    "flower that we want to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1712825024732,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "yG8pzm7xTqql",
    "outputId": "adc88ab4-b241-4cbd-beb1-52c9640c69bd"
   },
   "outputs": [],
   "source": [
    "print(\"Target Names:{}\".format(iris_dataset['target_names']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KV5V5VRTqql"
   },
   "source": [
    "The feature_names are a list of strings, giving the description of each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1712825024732,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "b8LAgb_xTqql",
    "outputId": "fb1ddb6f-bafd-41fc-8ade-6b6ffca2af72"
   },
   "outputs": [],
   "source": [
    "iris_dataset['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFkSkm67Tqql"
   },
   "source": [
    "The data itself is contained in the target and data fields. The data contains the\n",
    "numeric measurements of sepal length, sepal width, petal length, and petal width in a\n",
    "numpy array:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60QE0OgmTqql"
   },
   "source": [
    "The rows in the data array correspond to flowers, while the columns represent the\n",
    "four measurements that were taken for each flower:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1712825024733,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "TQt5g7ZLTqql",
    "outputId": "9cfd40c5-9ead-4782-a105-e127949908c9"
   },
   "outputs": [],
   "source": [
    "print(\"Shape of data:{}\".format(iris_dataset['data'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJO0lZ_ITqqm"
   },
   "source": [
    "We see that the data contains measurements for 150 different flowers.\n",
    "Remember that the individual items are called **samples** in machine learning, and their\n",
    "properties are called **features**.\n",
    "\n",
    "The **shape** of the data array is the number of samples times the number of features.\n",
    "\n",
    "This is a convention in scikit-learn, and your data will always be assumed to be in this\n",
    "shape.\n",
    "\n",
    "Here are the feature values for the first five samples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1712825024733,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "P_Q_L3KkTqqm",
    "outputId": "e38946bc-22ab-40d6-a062-d5988b4a1c6f"
   },
   "outputs": [],
   "source": [
    "print(\"First ten rows of data: \\n{}\".format(iris_dataset['data'][:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o3jYpOMTqqm"
   },
   "source": [
    "From this data, we can see that all of the first ten flowers have a petal width of 0.1 to 0.4 cm and that the sixth flower has the longest sepal, at 5.4 cm. The target array contains the species of each of the flowers that were measured. The target is a one-dimensional array, with one entry per flower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1712825024733,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "jugvB8CmTqqm",
    "outputId": "4bf7b0e1-d63e-4c4b-fead-e2e75c7e4d48"
   },
   "outputs": [],
   "source": [
    "iris_dataset['target'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWqhPtOUTqqm"
   },
   "source": [
    "The species are encoded as integers from 0 to 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1712825024733,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "T1MOkHPrTqqm",
    "outputId": "e31cff71-bfd9-458d-ad63-1ecd0c809e60"
   },
   "outputs": [],
   "source": [
    "iris_dataset['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fu_jkBKxTqqn"
   },
   "source": [
    "## Appendix 2: Iris Dataset - Basic Sensitivity Analysis\n",
    "\n",
    "Sensitivity analysis can be performed to understand how critical the features are of a kNN classifier. Consider the illustration below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1712825024733,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "NgxAEpWuTqqn",
    "outputId": "f683b14b-72e2-4cc7-9981-373a775e39b5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "iris_dataset = datasets.load_iris()\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "y =  iris_dataset.target\n",
    "number_features = iris_dataset.data.shape[1]\n",
    "\n",
    "print('Feature Added  Accuracy')\n",
    "for i in range(number_features):\n",
    "    X = iris_dataset.data[:, i].reshape(-1, 1)\n",
    "    scores = cross_val_score(clf, X, y)\n",
    "    print('%d        %g' % (i, scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1712825024733,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "rEm1JlTCTqqn",
    "outputId": "3a16b3ce-667e-4242-ef36-fde1ee3167f0"
   },
   "outputs": [],
   "source": [
    "iris_dataset['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URhvv6sGTqqn"
   },
   "source": [
    "These results suggest that classification is dominated by features 2 and 3. You could follow an alternative approach by removing one feature at a time and look for the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1712825024733,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "Azaf-vdOTqqn",
    "outputId": "a20d39a9-fb86-4c97-c30a-b35fd45b0a80"
   },
   "outputs": [],
   "source": [
    "print('Feature Removed  Accuracy')\n",
    "for i in range(number_features):\n",
    "    X_head = np.atleast_2d(iris_dataset.data[:, 0:i])\n",
    "    X_tail = np.atleast_2d(iris_dataset.data[:, i+1:])\n",
    "    X = np.hstack((X_head, X_tail))\n",
    "    scores = cross_val_score(clf, X, y)\n",
    "    print('%d        %g' % (i, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRRJsYaOTqqn"
   },
   "source": [
    "Consistent with the above you will see that features 2 and 3 gives the highest accuracy dips upon removal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XPCm6FsTqqo"
   },
   "source": [
    "## Appendix 3: Boston Cancer Dataset\n",
    "This contains some \"nice to learn programming notes\". The dataset consists of 569 data points, with 30 features each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1712825024733,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "ManQ8uUzTqqo",
    "outputId": "6fab5758-4de5-4c26-d6dc-ceafb5f32eb5"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer_dataset = load_breast_cancer()\n",
    "print(\"cancer.keys():\\n{}\".format(cancer_dataset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1712825024733,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "eNmfbc5mTqqo",
    "outputId": "0575fa0f-a013-4d0d-96cc-cc4ff6b6091e"
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(cancer_dataset['data']) #Feature variables\n",
    "df.columns=cancer_dataset['feature_names'] #ADD the feature_names as column labels\n",
    "df['Target'] = cancer_dataset['target'] #ADD the target as another column\n",
    "df.head(10) #DISPLAY the first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1712825024733,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "QNtXeEa0Tqqo",
    "outputId": "09ea2b44-87e2-4150-d5b3-f3ca77cf3ead"
   },
   "outputs": [],
   "source": [
    "print(cancer_dataset.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHMtytnKTqqp"
   },
   "source": [
    "Of these 569 data points, 212 are labeled as malignant, and 357 as benign:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1712825024733,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "qT25WHeoTqqp",
    "outputId": "b71220d4-28d7-4978-edad-31461c928969"
   },
   "outputs": [],
   "source": [
    "print(cancer_dataset.target_names)\n",
    "print(np.bincount(cancer_dataset.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_5RsDnkTqqp"
   },
   "source": [
    "To get a description of the semantic meaning of each feature, we can have a look at\n",
    "the feature_names attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1712825024733,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "SkpBINFsTqqp",
    "outputId": "d3603684-be74-4bbd-ff99-60e4d302fb77"
   },
   "outputs": [],
   "source": [
    "cancer_dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHxXKPUATqqp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_dataset['data'], cancer_dataset['target'],test_size=0.25,\n",
    "random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bk0Y7CXTqqq"
   },
   "source": [
    "## Appendix 4: Boston Cancer Dataset - Deeper Exploration\n",
    "Some methods below will allow you to manipulate the above data and might be useful for allowing you to have an \"Excel\"-like feel to better appreciate the complexity of the data.\n",
    "\n",
    "You can select columns to visualise in scatterplot just a few features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1712825024733,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "d85CMPWpTqqq",
    "outputId": "63dc27a9-ed34-4f92-8f89-92bab3df0d8b"
   },
   "outputs": [],
   "source": [
    "cancer_dataset['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1712825024733,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "fVjDotryTqqq",
    "outputId": "d6ed0f48-c60a-4b0f-88e0-8143a455455b"
   },
   "outputs": [],
   "source": [
    "select_columns = ['mean radius', 'mean texture', 'mean perimeter', 'mean area','Target']\n",
    "cancer_dataset_group1 = pd.DataFrame(df, columns=select_columns) #Consider only the columns given and call it group 1\n",
    "df1=cancer_dataset_group1\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1712825024733,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "E94oIfsoTqqq",
    "outputId": "73605314-42e5-4117-e5c8-297273794e25"
   },
   "outputs": [],
   "source": [
    "select_columns = ['worst concavity','worst smoothness', 'worst symmetry', 'worst fractal dimension','Target']\n",
    "cancer_dataset_group2 = pd.DataFrame(df, columns=select_columns) #Consider only the columns given and call it group 2\n",
    "df2=cancer_dataset_group2\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1712825024734,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "e6II5_NMTqqr",
    "outputId": "00baa7eb-1795-4977-9409-dbac0b77f4c3"
   },
   "outputs": [],
   "source": [
    "cancer_dataset_group2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 9101,
     "status": "ok",
     "timestamp": 1712825033828,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "CDbpxs95Tqqr",
    "outputId": "2c9b5ae0-3393-4182-bb24-3a7fb0106ab7"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "df = cancer_dataset_group1\n",
    "sns.pairplot(df, hue=\"Target\")\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7567,
     "status": "ok",
     "timestamp": 1712825041391,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "Y1x8m-QPTqqr",
    "outputId": "9d998012-4476-4307-8b39-7a07cf7c74ce"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "df = cancer_dataset_group2\n",
    "sns.pairplot(df, hue=\"Target\")\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewVe1B4CTqqr"
   },
   "source": [
    "Clearly, we can observe separation lines resulting from the features provided in this feature group. For die hard excel fans, the following commands might be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3R559wg4Tqqs"
   },
   "outputs": [],
   "source": [
    "df.to_csv(data_dir+'ExcelDieHard.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8PEyojxTqqs"
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(data_dir+'ExcelDieHard.xlsx')\n",
    "df1.to_excel(writer,'Sheet1')\n",
    "df2.to_excel(writer,'Sheet2')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Ly0ZDrhTqqs"
   },
   "outputs": [],
   "source": [
    "df_sheet1 = pd.read_excel(data_dir+'ExcelDieHard.xlsx', sheet_name=\"Sheet1\")\n",
    "dummy=df_sheet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiEdqzT1Tqqs"
   },
   "outputs": [],
   "source": [
    "df_features=dummy.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1712826558309,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "VrVNQm1cTqqs",
    "outputId": "bf7913be-0049-449c-9b01-c35e55c9d42e"
   },
   "outputs": [],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1712826558842,
     "user": {
      "displayName": "kc-aim",
      "userId": "16968997735368758960"
     },
     "user_tz": -480
    },
    "id": "F1RIBGbyTqqs",
    "outputId": "7c47069b-bc36-4c51-ada3-188a171d5858",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sheet1.head()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
